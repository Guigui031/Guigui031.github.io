---
title: "Metadata curation to evaluate the use of LLMs in the context of a systematic review"
description: "This project is about collecting metadata from articles in systematic reviews to create clean datasets. The developped program performs automatic data cleaning, definition, and alignment for all these articles. The datasets are used by a Mila-affiliated M.Sc. student to evaluate the use of LLMs in the screening phase of systematic review."
pubDate: 2023-06-01
heroImage: "/ProjetCurationMetadonnees.png"
badge: "Research"
tags: ["LLM", "Data Curation", "Systematic Review", "Mila", "Research"]
githubUrl: "https://github.com/geodes-sms/IFT3150-ProjetCurationMetadonnees"
category: "machine-learning"
titleFr: "Curation de métadonnées pour évaluer l'utilisation des LLM dans le contexte d'une revue systématique"
descriptionFr: "Ce projet consiste à collecter les métadonnées d'articles dans des revues systématiques pour créer des jeux de données propres. Le programme développé effectue un nettoyage automatique, une définition et un alignement des données pour tous ces articles. Les jeux de données sont utilisés par un étudiant à la maîtrise affilié à Mila pour évaluer l'utilisation des LLM dans la phase de sélection des revues systématiques."
badgeFr: "Recherche"
contentFr: |
  # Curation de métadonnées pour l'évaluation LLM en revues systématiques

  Un projet de recherche collaborative axé sur la préparation de jeux de données de haute qualité pour évaluer les grands modèles de langage dans les processus de revues systématiques.

  ## Contexte du projet

  Ce projet a été développé en collaboration avec un étudiant à la maîtrise affilié à Mila pour soutenir la recherche sur l'utilisation des grands modèles de langage dans la phase de sélection des revues systématiques - une étape critique dans la méthodologie de recherche académique.

  ## Objectifs du projet

  ### Buts principaux
  - **Création de jeux de données** : Construire des jeux de données propres et structurés à partir d'articles de revues systématiques
  - **Extraction de métadonnées** : Collecter des métadonnées complètes d'articles de recherche
  - **Assurance qualité des données** : Assurer que les jeux de données répondent aux standards de recherche pour l'évaluation LLM
  - **Support de recherche** : Permettre l'évaluation systématique des capacités LLM dans le screening académique

  ## Implémentation technique

  ### Pipeline de collecte de données
  - **Extraction automatisée** : Collecte systématique de métadonnées d'articles
  - **Intégration de sources** : Gestion de multiples sources et formats de données
  - **Contrôle qualité** : Mécanismes de validation pour l'intégrité des données

  ### Fonctionnalités de traitement des données
  - **Nettoyage automatique** : Suppression intelligente d'inconsistances et erreurs
  - **Définition des données** : Standardisation des champs et formats de métadonnées
  - **Algorithmes d'alignement** : Correspondance et harmonisation des données entre sources
  - **Validation de schéma** : Assurance de conformité aux standards de recherche

  ### Intégration de recherche
  - **Collaboration Mila** : Support direct pour recherche de maîtrise en cours
  - **Évaluation LLM** : Jeux de données spécifiquement conçus pour l'évaluation de modèles
  - **Contexte de revue systématique** : Compréhension des exigences spécifiques au domaine

  ## Architecture technique

  ### Pipeline de traitement
  - **Ingestion de données** : Extraction robuste depuis multiples sources académiques
  - **Normalisation** : Conversion vers formats standardisés pour cohérence
  - **Validation** : Vérifications automatisées de qualité et complétude
  - **Export structuré** : Génération de jeux de données prêts pour la recherche

  ### Systèmes de qualité

  #### Assurance qualité automatisée
  - **Validation de schéma** : Vérification de conformité structurelle
  - **Détection d'anomalies** : Identification de données potentiellement problématiques
  - **Métriques de complétude** : Évaluation quantitative de la couverture des données
  - **Traçabilité** : Suivi de provenance pour audit et reproduction

  #### Standards de recherche
  - **Méthodologie reproductible** : Processus documenté pour réplication
  - **Contrôle de version** : Gestion des versions de jeux de données
  - **Documentation complète** : Spécifications détaillées pour utilisateurs de recherche
  - **Conformité éthique** : Respect des standards de recherche académique

  ## Stack technique

  ### Technologies principales
  - **Python** : Langage de développement central
  - **Bibliothèques de traitement de données** : Pandas, NumPy pour manipulation de données
  - **Traitement du langage naturel** : Extraction et traitement de métadonnées textuelles
  - **Outils de recherche** : APIs de bases de données académiques et outils de traitement

  ### Infrastructure de données
  - **Bases de données relationnelles** : Stockage structuré pour métadonnées
  - **Systèmes de fichiers** : Gestion de documents et ressources
  - **Pipelines ETL** : Extraction, transformation et chargement automatisés
  - **Outils de validation** : Vérification automatisée de qualité des données

  ## Impact et applications

  ### Contribution à la recherche
  - Permettre l'évaluation systématique des LLM dans des contextes académiques
  - Soutenir l'évaluation basée sur des preuves des capacités de l'IA
  - Contribuer à l'avancement des revues systématiques automatisées

  ### Innovation méthodologique
  - Pipeline automatisé pour préparation de données de recherche
  - Cadres d'assurance qualité pour jeux de données de recherche
  - Workflows de traitement de données reproductibles

  ## Défis techniques

  ### Hétérogénéité des données
  - **Formats variés** : Intégration de multiples formats de métadonnées académiques
  - **Standards inconsistants** : Harmonisation entre différents systèmes de publication
  - **Langues multiples** : Gestion de contenu multilingue dans la littérature
  - **Évolution temporelle** : Adaptation aux changements de standards au fil du temps

  ### Assurance qualité
  - **Validation à grande échelle** : Vérification efficace de grands volumes de données
  - **Détection d'erreurs subtiles** : Identification de problèmes non évidents
  - **Équilibrage automatisation/manuel** : Optimisation du ratio efficacité/précision
  - **Métriques de qualité** : Développement d'indicateurs de qualité appropriés

  ## Collaboration et impact

  ### Partenariat académique
  - **Collaboration directe** : Travail étroit avec chercheur Mila
  - **Transfert de connaissances** : Partage d'expertise en curation de données
  - **Support méthodologique** : Assistance pour conception d'expériences
  - **Livraison orientée recherche** : Produits adaptés aux besoins de recherche spécifiques

  ### Impact sur la communauté
  - **Standards de données** : Contribution aux meilleures pratiques de curation
  - **Outils open source** : Mise à disposition d'outils pour la communauté
  - **Publications académiques** : Support pour publications de recherche
  - **Formation** : Partage de méthodologies avec autres chercheurs

  ## Applications futures

  ### Extensions de recherche
  - **Domaines additionnels** : Application à d'autres types de revues systématiques
  - **Intégration avancée** : Connexion avec autres frameworks d'évaluation LLM
  - **Analyse temporelle** : Étude de l'évolution des publications dans le temps
  - **Métriques avancées** : Développement d'indicateurs de qualité sophistiqués

  ### Développements techniques
  - **Automatisation accrue** : Réduction de l'intervention manuelle
  - **Traitement en temps réel** : Intégration continue de nouvelles publications
  - **Interface utilisateur** : Outils graphiques pour chercheurs non-techniques
  - **API et intégrations** : Services pour utilisation par d'autres systèmes

  ## Directions de recherche futures

  - Extension à d'autres domaines de revues systématiques
  - Intégration avec d'autres frameworks d'évaluation LLM
  - Développement de systèmes de screening automatisés
  - Capacités de traitement de données en temps réel

  ## Collaboration

  Ce projet représente une collaboration réussie entre recherche académique (Mila) et développement logiciel pratique, démontrant l'importance de la préparation de données de haute qualité dans la recherche en IA.

  Ce projet illustre l'intersection critique entre l'ingénierie de données et la recherche en intelligence artificielle, montrant comment une préparation rigoureuse des données permet des évaluations significatives des capacités des grands modèles de langage dans des applications académiques réelles.
---

# Metadata Curation for LLM Evaluation in Systematic Reviews

A research collaboration project focused on preparing high-quality datasets to evaluate Large Language Models in systematic review processes.

## Project Context

This project was developed in collaboration with a Mila-affiliated M.Sc. student to support research on using Large Language Models in the screening phase of systematic reviews - a critical step in academic research methodology.

## Project Objectives

### Primary Goals
- **Dataset Creation**: Build clean, structured datasets from systematic review articles
- **Metadata Extraction**: Collect comprehensive metadata from research articles
- **Data Quality Assurance**: Ensure datasets meet research standards for LLM evaluation
- **Research Support**: Enable systematic evaluation of LLM capabilities in academic screening

## Technical Implementation

### Data Collection Pipeline
- **Automated Extraction**: Systematic collection of article metadata
- **Source Integration**: Handling multiple data sources and formats
- **Quality Control**: Validation mechanisms for data integrity

### Data Processing Features
- **Automatic Cleaning**: Intelligent removal of inconsistencies and errors
- **Data Definition**: Standardization of metadata fields and formats
- **Alignment Algorithms**: Matching and harmonizing data across sources
- **Schema Validation**: Ensuring compliance with research standards

### Research Integration
- **Mila Collaboration**: Direct support for ongoing M.Sc. research
- **LLM Evaluation**: Datasets specifically designed for model assessment
- **Systematic Review Context**: Understanding of domain-specific requirements

## Technical Stack

- **Python**: Core development language
- **Data Processing Libraries**: Pandas, NumPy for data manipulation
- **Natural Language Processing**: Text processing and metadata extraction
- **Research Tools**: Academic database APIs and processing tools

## Impact & Applications

### Research Contribution
- Enabling systematic evaluation of LLMs in academic contexts
- Supporting evidence-based assessment of AI capabilities
- Contributing to the advancement of automated systematic reviews

### Methodology Innovation
- Automated pipeline for research data preparation
- Quality assurance frameworks for research datasets
- Reproducible data processing workflows

## Collaboration

This project represents a successful collaboration between academic research (Mila) and practical software development, demonstrating the importance of high-quality data preparation in AI research.

## Future Research Directions

- Extension to additional systematic review domains
- Integration with other LLM evaluation frameworks
- Automated screening system development
- Real-time data processing capabilities